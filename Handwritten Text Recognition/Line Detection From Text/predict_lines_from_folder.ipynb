{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predict_lines_from_folder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtMEXaLmR7xN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K08lFDT-UBhv",
        "colab_type": "code",
        "outputId": "d2c06cf5-c8bf-4860-b6e1-92180912a4fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qat2DeArSJp7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class YOLO(nn.Module):\n",
        "    def __init__(self, img_width, row_size):\n",
        "        super(YOLO, self).__init__()\n",
        "        self.row_size = row_size\n",
        "        self.conv1 = nn.Conv2d(1, 16, 7, stride=2)\n",
        "        self.mp1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, (3, 3), stride=1)\n",
        "        self.mp2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, (3, 3), stride=1)\n",
        "        self.mp3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(64*53*36, 4096)\n",
        "        self.fc2 = nn.Linear(4096, row_size * 5)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv + ReLU + max pooling for two layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.mp1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.mp2(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.mp3(x)\n",
        "        x = x.view(-1, 64*53*36)\n",
        "        x = F.relu(self.dropout(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        x = x.view(-1, self.row_size, 5)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGqUCdS1SUdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_x_y(row, tensor):\n",
        "    \"\"\"calc coordinates\"\"\"\n",
        "\n",
        "    x = tensor[1] * 619\n",
        "    y = tensor[2] * (885 / 50) + row * (885 / 50)\n",
        "    width = tensor[3] * 619\n",
        "    height = tensor[4] * 885\n",
        "    return torch.FloatTensor([1, x, y, width, height])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_yaRBYwSaRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_box(tensor):\n",
        "    \"\"\"calc box for output line\"\"\"\n",
        "    x1 = max(0, tensor[1] - 0.5 * tensor[3])\n",
        "    y1 = max(0, tensor[2] - 0.5 * tensor[4])\n",
        "    x2 = min(619, tensor[1] + 0.5 * tensor[3])\n",
        "    y2 = min(885, tensor[2] + 0.5 * tensor[4])\n",
        "\n",
        "    box = [x1, y1, x2, y2]\n",
        "    return box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_3FYRneUPM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def non_maximum_suppression(tensor, percent):\n",
        "    \"\"\"choose predicted lines by highest propability. \n",
        "    Lines who overlap a actual choosen line by percent or higher will delete.\"\"\"\n",
        "    \n",
        "    for j in range(tensor.size(1)):\n",
        "        if(tensor[j,0].item() < 0.5):\n",
        "            tensor[j,0] = torch.tensor(0)\n",
        "    found = []\n",
        "    while(True):\n",
        "        maximum = 0\n",
        "        index = 0\n",
        "        for j in range(tensor.size(1)):\n",
        "            if(tensor[j,0].item() > maximum and j not in found):\n",
        "                maximum = tensor[j,0].item()\n",
        "                index = j\n",
        "\n",
        "        if(maximum == 0):\n",
        "            break\n",
        "\n",
        "        found.append(index)\n",
        "        tensor[index,0] = torch.tensor(1)\n",
        "            \n",
        "        for j in range(tensor.size(1)):\n",
        "            if(j != index and tensor[j,0] >= 0.5):\n",
        "                x_y_max = calc_x_y(index, tensor[index])\n",
        "                x_y_other = calc_x_y(j, tensor[j])\n",
        "                box1 = calc_box(x_y_max)\n",
        "                box2 = calc_box(x_y_other)\n",
        "                if(calc_iou(box1, box2) > percent):\n",
        "                    tensor[j,0] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4OPooVeSiBn",
        "colab_type": "code",
        "outputId": "e1b1561c-bd30-4fb0-d38b-afce8818fd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "imgs_path = \"drive/My Drive/data_small/forms/forms_train_small/\"\n",
        "imgs_paths = os.listdir(imgs_path)\n",
        "weight_path = \"drive/My Drive/evaluation_small/weights_small.pt\"\n",
        "predict_path = \"drive/My Drive/testlines_predicted_small/\"\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((885, 619)),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "# set a boolean flag that indicates whether a cuda capable GPU is available\n",
        "is_gpu = torch.cuda.is_available()\n",
        "print(\"GPU is available:\", is_gpu)\n",
        "print(\"If you are receiving False, try setting your runtime to GPU\")\n",
        "\n",
        "# set the device to cuda if a GPU is available\n",
        "device = torch.device(\"cuda\" if is_gpu else \"cpu\")\n",
        "model = torch.load(weight_path)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available: True\n",
            "If you are receiving False, try setting your runtime to GPU\n",
            "YOLO(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(7, 7), stride=(2, 2))\n",
            "  (mp1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (mp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=122112, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=250, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XztAz_3AuaCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_lines(model,imgs_path, predict_path):\n",
        "    \"\"\" predict images to lines from image path to predict_path\"\"\"\n",
        "    img_count = 0\n",
        "    for path in imgs_paths:\n",
        "        count = 0\n",
        "        img_tensor = transform(Image.open(imgs_path + path))\n",
        "        output = model(torch.stack([img_tensor]).to(device))[0]\n",
        "        # find right boxes\n",
        "        non_maximum_suppression(output, 0.5)\n",
        "        img = imageio.imread(imgs_path + path)\n",
        "        yscale = round(img.shape[0] / 885)\n",
        "        xscale = round(img.shape[1] / 619)\n",
        "        print(xscale, xscale)\n",
        "        for i in range(50):\n",
        "            if(output[i][0] > 0.5):\n",
        "                print(output[i])\n",
        "                box = calc_box(calc_x_y(i, output[i]))\n",
        "                x1 = (int(box[0])) * xscale\n",
        "                x2 = (int(box[2])) * xscale\n",
        "                y1 = (int(box[1])) * yscale\n",
        "                y2 = (int(box[3])) * yscale\n",
        "                print(box)\n",
        "                imageio.imwrite(predict_path + \"pic\" + str(img_count) + \"line\" + str(count) + '.jpg', img[y1:y2, x1:x2])\n",
        "                count += 1\n",
        "        img_count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03nLv2TGA2Vt",
        "colab_type": "code",
        "outputId": "4e941088-532f-445b-c2d6-28cf42674800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "predict_lines(model, imgs_path, predict_path)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 4\n",
            "tensor([0.9624, 0.5155, 0.2458, 0.7337, 0.0322], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(92.0245), tensor(184.8153), tensor(546.1631), tensor(213.2853)]\n",
            "tensor([0.9611, 0.5311, 0.7832, 0.7651, 0.0283], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(91.9314), tensor(231.4322), tensor(565.5098), tensor(256.4917)]\n",
            "tensor([0.9774, 0.5564, 0.3270, 0.7862, 0.0289], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(101.0668), tensor(276.1984), tensor(587.7156), tensor(301.7772)]\n",
            "tensor([0.9356, 0.5376, 0.7916, 0.7765, 0.0302], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(92.4154), tensor(319.2509), tensor(573.0753), tensor(345.9702)]\n",
            "tensor([0.9861, 0.5391, 0.4071, 0.7786, 0.0331], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(92.7140), tensor(364.2780), tensor(574.6712), tensor(393.5328)]\n",
            "tensor([0.9241, 0.5441, 0.8382, 0.7767, 0.0290], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(96.4169), tensor(409.0951), tensor(577.1865), tensor(434.7762)]\n",
            "tensor([0.9694, 0.5316, 0.4824, 0.7791, 0.0314], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "[tensor(87.9115), tensor(454.8552), tensor(570.1580), tensor(482.6223)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWycXvnbU9vU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}