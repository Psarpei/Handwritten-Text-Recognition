{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMHuASCNzsCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from os import listdir\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "from PIL import Image\n",
        "import glob\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVoDIXjV0AIU",
        "colab_type": "code",
        "outputId": "ba898fa0-5fed-46ec-9d45-17807e89593f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vNZm2NW0Ckp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class YOLO(nn.Module):\n",
        "    def __init__(self, img_width, row_size, col_size):\n",
        "        super(YOLO, self).__init__()\n",
        "        self.row_size = row_size\n",
        "        self.col_size = col_size\n",
        "        self.conv1 = nn.Conv2d(1, 16, 7, stride=2)\n",
        "        self.mp1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, (3, 3), stride=1)\n",
        "        self.mp2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, (3, 3), stride=1)\n",
        "        self.mp3 = nn.MaxPool2d(2, 2)\n",
        "        self.conv4 = nn.Conv2d(64, 128, (3, 3), stride=1)\n",
        "        self.mp4 = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(128, 128, (3, 3), stride=1)\n",
        "        self.mp5 = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128*11*7, 4096)\n",
        "        self.fc2 = nn.Linear(4096, self.row_size * self.col_size * 5)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Conv + ReLU + max pooling for two layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        #print(x.size())\n",
        "        x = self.mp1(x)\n",
        "        #print(x.size())\n",
        "        x = F.relu(self.conv2(x))\n",
        "        #print(x.size())\n",
        "        x = self.mp2(x)\n",
        "        #print(x.size())\n",
        "        x = F.relu(self.conv3(x))\n",
        "        #print(x.size())\n",
        "        x = self.mp3(x)\n",
        "        #print(x.size())\n",
        "        x = F.relu(self.conv4(x))\n",
        "        #print(x.size())\n",
        "        x = self.mp4(x)\n",
        "        #print(x.size())\n",
        "        x = F.relu(self.conv5(x))\n",
        "        #print(x.size())\n",
        "        x = self.mp5(x)\n",
        "        #print(x.size())\n",
        "        x = x.view(-1, 128*11*7)\n",
        "        x = F.relu(self.dropout(self.fc1(x)))\n",
        "        #print(x.size())\n",
        "        x = self.fc2(x)\n",
        "        #print(x.size())\n",
        "        x = x.view(-1, self.row_size, self.col_size, 5)\n",
        "        #print(x.size())\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBcfKq0-0kDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data(row_size, col_size, batch_size, transform, imgs_path, xmls_path): #range_num, train_bool):\n",
        "    data_list = []\n",
        "    target_list = []\n",
        "    data = []\n",
        "\n",
        "    imgs = os.listdir(imgs_path)\n",
        "    imgs.sort()\n",
        "    xmls = os.listdir(xmls_path)\n",
        "    xmls.sort()\n",
        "\n",
        "    for i in range(len(imgs)):\n",
        "        line_count = 1\n",
        "        img = Image.open(imgs_path + imgs[i])\n",
        "        img_tensor = transform(img)\n",
        "        data_list.append((img_tensor))\n",
        "        row_height = img_tensor.size(1) / row_size\n",
        "        row_width = img_tensor.size(2) / col_size\n",
        "\n",
        "        tree = ET.parse(xmls_path + xmls[i])\n",
        "        root = tree.getroot()\n",
        "\n",
        "        target = [[[0, 0, 0, 0, 0] for i in range(col_size)] for i in range(row_size)]\n",
        "\n",
        "        for line in root[1]:  # root[1] catches handwritten part\n",
        "            word_count = 1\n",
        "            for word in line:\n",
        "                if (word.tag == \"word\"):  # there isn't only words lines\n",
        "                    x1 = 999999999999999\n",
        "                    y1 = 999999999999999\n",
        "                    y2 = 0\n",
        "                    width = 0\n",
        "                    for char in word:\n",
        "                        x1 = min(x1, int(char.attrib[\"x\"]) * percent / 100)\n",
        "                        y1 = min(y1, int(char.attrib[\"y\"]) * percent / 100)\n",
        "                        y2 = max(y2, (int(char.attrib[\"y\"]) + int(char.attrib[\"height\"])) * percent / 100)\n",
        "                        width = int(char.attrib[\"x\"]) * percent / 100 - x1 + int(char.attrib[\"width\"]) * percent / 100\n",
        "\n",
        "                    x2 = x1 + width\n",
        "                    if(x1 == 999999999999999):\n",
        "                        continue\n",
        "\n",
        "                    b_x = x1/2 + x2/2\n",
        "                    b_y = y1/2 + y2/2\n",
        "                    b_w = x2-x1\n",
        "                    b_h = y2-y1\n",
        "            \n",
        "                    row = int(b_y // row_height)\n",
        "                    col = int(b_x // row_width)\n",
        "\n",
        "                    b_box = [1, (b_x % row_width) / row_width, (b_y % row_height) / row_height, b_w / img_tensor.size(2), b_h / img_tensor.size(1)]\n",
        "                    target[row][col] = b_box\n",
        "\n",
        "                    word_count += 1\n",
        "\n",
        "            line_count += 1\n",
        "\n",
        "        del(root)\n",
        "        del(tree)\n",
        "        del(img)\n",
        "        del(img_tensor)\n",
        "        target = torch.FloatTensor(target)\n",
        "        target_list.append(target)\n",
        "        del(target)\n",
        "        if len(data_list) >= batch_size:\n",
        "            data.append((torch.stack(data_list), torch.stack(target_list)))\n",
        "            del(data_list)\n",
        "            del(target_list)\n",
        "            data_list = []\n",
        "            target_list = []\n",
        "            print('Loaded batch ', len(data), 'of ', int(len(listdir(imgs_path)) / batch_size))\n",
        "            print('Percentage Done: ',\n",
        "                  100 * (len(data)) / int(len(listdir(imgs_path)) / batch_size), '%')\n",
        "\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ1vqfBy0mD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_data, model, optimizer, device):\n",
        "    \"\"\"\n",
        "    Trains/updates the model for one epoch on the training dataset.\n",
        "\n",
        "    Parameters:\n",
        "        train_data (torch tensor): The trainset\n",
        "        model (torch.nn.module): Model to be trained\n",
        "        optimizer (torch.optim.optimizer): optimizer instance like SGD or Adam\n",
        "        device (string): cuda or cpu\n",
        "    \"\"\"\n",
        "\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    # iterate through the dataset loader\n",
        "    i = 0\n",
        "    losses = []\n",
        "    ious = []\n",
        "    for (inp, target) in train_data:\n",
        "        # transfer inputs and targets to the GPU (if it is available)\n",
        "        inp = inp.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # compute output, i.e. the model forward\n",
        "        output = model(inp)\n",
        "\n",
        "        # print(\"output\", output.size(), \"target\", target.size())\n",
        "        # calculate the loss\n",
        "\n",
        "        loss = yolo_loss(output, target)\n",
        "        #print(\"loss\", loss)\n",
        "        if (i == 0):\n",
        "            print(output[0][9])\n",
        "            print(target[0][9])\n",
        "        i += 1\n",
        "        iou = calc_mean_iou(output, target)\n",
        "        print(\"loss {:.2} IOU {:.2}\".format(loss,iou))\n",
        "        ious.append(iou)\n",
        "\n",
        "        # compute gradient and do the SGD step\n",
        "        # we reset the optimizer with zero_grad to \"flush\" former gradients\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBAzTGFs0l0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(val_dataset, model, device, percent):\n",
        "    model.eval()\n",
        "\n",
        "    # avoid computation of gradients and necessary storing of intermediate layer activations\n",
        "    with torch.no_grad():\n",
        "        # iterate through the dataset loader\n",
        "        losses = []\n",
        "        ious = []\n",
        "        accs = []\n",
        "        precs = []\n",
        "        recs = []\n",
        "\n",
        "        for (inp, target) in val_dataset:\n",
        "            # transfer to device\n",
        "            inp = inp.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            # compute output\n",
        "            output = model(inp)\n",
        "\n",
        "            # find right boxes\n",
        "            #calc_better_output(output, percent)\n",
        "\n",
        "            # compute loss\n",
        "            loss = yolo_loss(output, target)\n",
        "            iou = calc_mean_iou(output, target)\n",
        "            acc = calc_accuracy(output, target, percent)\n",
        "            prec = calc_precision(output, target, percent)\n",
        "            rec = calc_recall(output, target, percent) \n",
        "\n",
        "            losses.append(loss)\n",
        "            ious.append(iou)\n",
        "            accs.append(acc)\n",
        "            precs.append(prec)\n",
        "            recs.append(rec)\n",
        "\n",
        "            print(\"loss {:.2} IOU {:.2}\".format(loss,iou))\n",
        "            #print(\"IOU\", iou)\n",
        "    avg_loss = torch.mean(torch.stack(losses)).item()\n",
        "    avg_iou = torch.mean(torch.stack(ious)).item()\n",
        "    avg_acc = sum(accs) / len(accs)\n",
        "    avg_prec = sum(precs) / len(precs)\n",
        "    avg_rec = sum(recs) / len(recs)\n",
        "    print(\"avg. loss {:.2} avg. IOU {:.2} avg. acc {:.2} avg. prec {:.2} avg. rec {:.2}\".format(avg_loss, avg_iou, avg_acc, avg_prec, avg_rec))\n",
        "\n",
        "    return [avg_loss, avg_iou, avg_acc, avg_prec, avg_rec]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVQWwG2k1QTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def yolo_loss(output, target):\n",
        "    lambda_coord = 5\n",
        "    lambda_noob = 0.5\n",
        "    errors = []\n",
        "    for i in range(output.size(0)):\n",
        "        error1 = 0\n",
        "        error2 = 0\n",
        "        error3 = 0\n",
        "        error4 = 0\n",
        "        for j in range(output.size(1)):\n",
        "            for k in range(output.size(2)):\n",
        "                if (target[i][j][k][0] == 1.0):\n",
        "                    error1 += (target[i][j][k][1] - output[i][j][k][1]) ** 2 + (target[i][j][k][2] - output[i][j][k][2]) ** 2\n",
        "                    error2 += (target[i][j][k][3] - output[i][j][k][3]) ** 2 + (target[i][j][k][4] - output[i][j][k][4]) ** 2 \n",
        "                    error3 += (target[i][j][k][0] - output[i][j][k][0]) ** 2\n",
        "                else: \n",
        "                    error4 += (target[i][j][k][0] - output[i][j][k][0]) ** 2\n",
        "        error = lambda_coord * error1 + lambda_coord * error2 + error3 + lambda_noob * error4\n",
        "        errors.append(error)\n",
        "    return torch.mean(torch.stack(errors))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c7-u5zr1V4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_iou(box1, box2):\n",
        "    # calculate the coordinates of the insersection rectangle\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    # calculate the area of intersetion rectangle\n",
        "    intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
        "\n",
        "    # calculate the area of the single boxes\n",
        "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
        "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
        "\n",
        "    iou = intersection / (box1_area + box2_area - intersection)\n",
        "\n",
        "    return iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZdsgrNI1aq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_x_y(row, col, tensor):\n",
        "    x = tensor[1] * (619 / 20) + col * (619 / 20)\n",
        "    y = tensor[2] * (885 / 30) + row * (885 / 30)\n",
        "    width = tensor[3] * 619\n",
        "    height = tensor[4] * 885\n",
        "    return torch.FloatTensor([1, x, y, width, height])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhhH4RYW1gwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_mean_iou(output, target):\n",
        "    iou_list = []\n",
        "    for i in range(output.size(0)):\n",
        "        ious = []\n",
        "        for j in range(output.size(1)):\n",
        "            for k in range(output.size(2)):\n",
        "                if (target[i][j][k][0] == 1):\n",
        "                    x_y_target = calc_x_y(j, k, target[i, j, k])\n",
        "                    x_y_output = calc_x_y(j, k, output[i, j, k])\n",
        "                    box1 = calc_box(x_y_target)\n",
        "                    box2 = calc_box(x_y_output)\n",
        "                    ious.append(calc_iou(box1, box2))\n",
        "        iou_list.append(torch.mean(torch.stack(ious)))\n",
        "\n",
        "    mean_iou = torch.mean(torch.stack(iou_list))\n",
        "    return mean_iou"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQiMxho1ihy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_box(tensor):\n",
        "    x1 = max(0, tensor[1] - 0.5 * tensor[3])\n",
        "    y1 = max(0, tensor[2] - 0.5 * tensor[4])\n",
        "    x2 = min(619, tensor[1] + 0.5 * tensor[3])\n",
        "    y2 = min(885, tensor[2] + 0.5 * tensor[4])\n",
        "\n",
        "    box = [x1, y1, x2, y2]\n",
        "    return box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AvaMPcq1tKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(output, target, percent):\n",
        "    acc_list = []\n",
        "    for i in range(output.size(0)):\n",
        "        for j in range(output.size(1)):\n",
        "            for k in range(output.size(2)):\n",
        "                if (target[i][j][k][0] == 1):\n",
        "                    acc_list.append(1 if (output[i][j][k][0] >= percent) else 0)\n",
        "                else:\n",
        "                    acc_list.append(1 if (output[i][j][k][0] < percent) else 0)\n",
        "    acc = sum(acc_list) / len(acc_list) if(sum(acc_list) > 0) else 0 \n",
        "    return acc "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17kvI9d31x8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_precision(output, target, percent):\n",
        "    prec_list = []\n",
        "    for i in range(output.size(0)):\n",
        "        for j in range(output.size(1)):\n",
        "            for k in range(output.size(2)):\n",
        "                if (output[i][j][k][0] >= percent):\n",
        "                    prec_list.append(1 if (target[i][j][k][0] == 1) else 0)\n",
        "    prec = sum(prec_list) / len(prec_list) if(sum(prec_list) > 0) else 0     \n",
        "    return sum(prec_list) / len(prec_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtWfVLFB10wt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_recall(output, target, percent):\n",
        "    rec_list = []\n",
        "    for i in range(output.size(0)):\n",
        "        for j in range(output.size(1)):\n",
        "              for k in range(output.size(2)):\n",
        "                  if (target[i][j][k][0] == 1):\n",
        "                      rec_list.append(1 if (output[i][j][k][0] >= percent) else 0)\n",
        "    \n",
        "    rec = sum(rec_list) / len(rec_list) if(sum(rec_list) > 0) else 0 \n",
        "    return rec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omr6BQJq180q",
        "colab_type": "code",
        "outputId": "dfe8a58e-47c0-4dd1-96b0-46c66bd965b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "imgs_train_path = 'drive/My Drive/data_small/forms/forms_train_small/'\n",
        "xmls_train_path = 'drive/My Drive/data_small/xmls/xml_train/'\n",
        "imgs_test_path = 'drive/My Drive/data_small/forms/forms_test_small/'\n",
        "xmls_test_path = 'drive/My Drive/data_small/xmls/xml_test/'\n",
        "\n",
        "weight_path = \"C:/Users/Pasca/Documents/Goethe-Uni/Master_1.Semester/Pattern_Analyis_Machine_Intelligence/Abschlussprojekt/sentence_detection_small_weights_10/weights\"\n",
        "\n",
        "percent = 25\n",
        "batch_size = 16 \n",
        "row_size = 30\n",
        "col_size = 20\n",
        "transform = transforms.Compose([transforms.Resize((885, 619)),\n",
        "                                    transforms.ToTensor()])\n",
        "\n",
        "train_data = create_data(row_size, col_size, batch_size, transform, imgs_train_path, xmls_train_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded batch  1 of  82\n",
            "Percentage Done:  1.2195121951219512 %\n",
            "Loaded batch  2 of  82\n",
            "Percentage Done:  2.4390243902439024 %\n",
            "Loaded batch  3 of  82\n",
            "Percentage Done:  3.658536585365854 %\n",
            "Loaded batch  4 of  82\n",
            "Percentage Done:  4.878048780487805 %\n",
            "Loaded batch  5 of  82\n",
            "Percentage Done:  6.097560975609756 %\n",
            "Loaded batch  6 of  82\n",
            "Percentage Done:  7.317073170731708 %\n",
            "Loaded batch  7 of  82\n",
            "Percentage Done:  8.536585365853659 %\n",
            "Loaded batch  8 of  82\n",
            "Percentage Done:  9.75609756097561 %\n",
            "Loaded batch  9 of  82\n",
            "Percentage Done:  10.975609756097562 %\n",
            "Loaded batch  10 of  82\n",
            "Percentage Done:  12.195121951219512 %\n",
            "Loaded batch  11 of  82\n",
            "Percentage Done:  13.414634146341463 %\n",
            "Loaded batch  12 of  82\n",
            "Percentage Done:  14.634146341463415 %\n",
            "Loaded batch  13 of  82\n",
            "Percentage Done:  15.853658536585366 %\n",
            "Loaded batch  14 of  82\n",
            "Percentage Done:  17.073170731707318 %\n",
            "Loaded batch  15 of  82\n",
            "Percentage Done:  18.29268292682927 %\n",
            "Loaded batch  16 of  82\n",
            "Percentage Done:  19.51219512195122 %\n",
            "Loaded batch  17 of  82\n",
            "Percentage Done:  20.73170731707317 %\n",
            "Loaded batch  18 of  82\n",
            "Percentage Done:  21.951219512195124 %\n",
            "Loaded batch  19 of  82\n",
            "Percentage Done:  23.170731707317074 %\n",
            "Loaded batch  20 of  82\n",
            "Percentage Done:  24.390243902439025 %\n",
            "Loaded batch  21 of  82\n",
            "Percentage Done:  25.609756097560975 %\n",
            "Loaded batch  22 of  82\n",
            "Percentage Done:  26.829268292682926 %\n",
            "Loaded batch  23 of  82\n",
            "Percentage Done:  28.048780487804876 %\n",
            "Loaded batch  24 of  82\n",
            "Percentage Done:  29.26829268292683 %\n",
            "Loaded batch  25 of  82\n",
            "Percentage Done:  30.48780487804878 %\n",
            "Loaded batch  26 of  82\n",
            "Percentage Done:  31.70731707317073 %\n",
            "Loaded batch  27 of  82\n",
            "Percentage Done:  32.926829268292686 %\n",
            "Loaded batch  28 of  82\n",
            "Percentage Done:  34.146341463414636 %\n",
            "Loaded batch  29 of  82\n",
            "Percentage Done:  35.36585365853659 %\n",
            "Loaded batch  30 of  82\n",
            "Percentage Done:  36.58536585365854 %\n",
            "Loaded batch  31 of  82\n",
            "Percentage Done:  37.80487804878049 %\n",
            "Loaded batch  32 of  82\n",
            "Percentage Done:  39.02439024390244 %\n",
            "Loaded batch  33 of  82\n",
            "Percentage Done:  40.24390243902439 %\n",
            "Loaded batch  34 of  82\n",
            "Percentage Done:  41.46341463414634 %\n",
            "Loaded batch  35 of  82\n",
            "Percentage Done:  42.68292682926829 %\n",
            "Loaded batch  36 of  82\n",
            "Percentage Done:  43.90243902439025 %\n",
            "Loaded batch  37 of  82\n",
            "Percentage Done:  45.1219512195122 %\n",
            "Loaded batch  38 of  82\n",
            "Percentage Done:  46.34146341463415 %\n",
            "Loaded batch  39 of  82\n",
            "Percentage Done:  47.5609756097561 %\n",
            "Loaded batch  40 of  82\n",
            "Percentage Done:  48.78048780487805 %\n",
            "Loaded batch  41 of  82\n",
            "Percentage Done:  50.0 %\n",
            "Loaded batch  42 of  82\n",
            "Percentage Done:  51.21951219512195 %\n",
            "Loaded batch  43 of  82\n",
            "Percentage Done:  52.4390243902439 %\n",
            "Loaded batch  44 of  82\n",
            "Percentage Done:  53.65853658536585 %\n",
            "Loaded batch  45 of  82\n",
            "Percentage Done:  54.8780487804878 %\n",
            "Loaded batch  46 of  82\n",
            "Percentage Done:  56.09756097560975 %\n",
            "Loaded batch  47 of  82\n",
            "Percentage Done:  57.31707317073171 %\n",
            "Loaded batch  48 of  82\n",
            "Percentage Done:  58.53658536585366 %\n",
            "Loaded batch  49 of  82\n",
            "Percentage Done:  59.75609756097561 %\n",
            "Loaded batch  50 of  82\n",
            "Percentage Done:  60.97560975609756 %\n",
            "Loaded batch  51 of  82\n",
            "Percentage Done:  62.19512195121951 %\n",
            "Loaded batch  52 of  82\n",
            "Percentage Done:  63.41463414634146 %\n",
            "Loaded batch  53 of  82\n",
            "Percentage Done:  64.63414634146342 %\n",
            "Loaded batch  54 of  82\n",
            "Percentage Done:  65.85365853658537 %\n",
            "Loaded batch  55 of  82\n",
            "Percentage Done:  67.07317073170732 %\n",
            "Loaded batch  56 of  82\n",
            "Percentage Done:  68.29268292682927 %\n",
            "Loaded batch  57 of  82\n",
            "Percentage Done:  69.51219512195122 %\n",
            "Loaded batch  58 of  82\n",
            "Percentage Done:  70.73170731707317 %\n",
            "Loaded batch  59 of  82\n",
            "Percentage Done:  71.95121951219512 %\n",
            "Loaded batch  60 of  82\n",
            "Percentage Done:  73.17073170731707 %\n",
            "Loaded batch  61 of  82\n",
            "Percentage Done:  74.39024390243902 %\n",
            "Loaded batch  62 of  82\n",
            "Percentage Done:  75.60975609756098 %\n",
            "Loaded batch  63 of  82\n",
            "Percentage Done:  76.82926829268293 %\n",
            "Loaded batch  64 of  82\n",
            "Percentage Done:  78.04878048780488 %\n",
            "Loaded batch  65 of  82\n",
            "Percentage Done:  79.26829268292683 %\n",
            "Loaded batch  66 of  82\n",
            "Percentage Done:  80.48780487804878 %\n",
            "Loaded batch  67 of  82\n",
            "Percentage Done:  81.70731707317073 %\n",
            "Loaded batch  68 of  82\n",
            "Percentage Done:  82.92682926829268 %\n",
            "Loaded batch  69 of  82\n",
            "Percentage Done:  84.14634146341463 %\n",
            "Loaded batch  70 of  82\n",
            "Percentage Done:  85.36585365853658 %\n",
            "Loaded batch  71 of  82\n",
            "Percentage Done:  86.58536585365853 %\n",
            "Loaded batch  72 of  82\n",
            "Percentage Done:  87.8048780487805 %\n",
            "Loaded batch  73 of  82\n",
            "Percentage Done:  89.02439024390245 %\n",
            "Loaded batch  74 of  82\n",
            "Percentage Done:  90.2439024390244 %\n",
            "Loaded batch  75 of  82\n",
            "Percentage Done:  91.46341463414635 %\n",
            "Loaded batch  76 of  82\n",
            "Percentage Done:  92.6829268292683 %\n",
            "Loaded batch  77 of  82\n",
            "Percentage Done:  93.90243902439025 %\n",
            "Loaded batch  78 of  82\n",
            "Percentage Done:  95.1219512195122 %\n",
            "Loaded batch  79 of  82\n",
            "Percentage Done:  96.34146341463415 %\n",
            "Loaded batch  80 of  82\n",
            "Percentage Done:  97.5609756097561 %\n",
            "Loaded batch  81 of  82\n",
            "Percentage Done:  98.78048780487805 %\n",
            "Loaded batch  82 of  82\n",
            "Percentage Done:  100.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76wp0glaCnBu",
        "colab_type": "code",
        "outputId": "459189c4-a323-4260-f237-42997452beab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "train_data[0][1][0][9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.3724, 0.6695, 0.0077, 0.0198],\n",
              "        [1.0000, 0.6607, 0.7034, 0.0291, 0.0153],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.2722, 0.7076, 0.0456, 0.0178],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.5339, 0.8220, 0.1135, 0.0130],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.6704, 0.7161, 0.0323, 0.0167],\n",
              "        [1.0000, 0.6074, 0.8093, 0.0258, 0.0099],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.8409, 0.8559, 0.1369, 0.0271],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.0057, 0.6864, 0.0368, 0.0209],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [1.0000, 0.1179, 0.7754, 0.1220, 0.0184],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mOWLKs22CUL",
        "colab_type": "code",
        "outputId": "5f3cd12d-45fe-4f3e-d3c6-f15a93347bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# set a boolean flag that indicates whether a cuda capable GPU is available\n",
        "# we will need this for transferring our tensors to the device and\n",
        "# for persistent memory in the data loader\n",
        "is_gpu = torch.cuda.is_available()\n",
        "print(\"GPU is available:\", is_gpu)\n",
        "print(\"If you are receiving False, try setting your runtime to GPU\")\n",
        "\n",
        "# set the device to cuda if a GPU is available\n",
        "device = torch.device(\"cuda\" if is_gpu else \"cpu\")\n",
        "\n",
        "weight_path = \"drive/My Drive/evaluation_small/weights_word_detection_small_new20.pt\"\n",
        "model = torch.load(weight_path)\n",
        "\n",
        "print(model)\n",
        "# optimizer\n",
        "print(model(train_data[0][0].to(device)))\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "#print(model(torch.stack([img_tensor, img_tensor]).to(device)))\n",
        "\n",
        "test_data = create_data(row_size, col_size, batch_size, transform, imgs_test_path, xmls_test_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available: True\n",
            "If you are receiving False, try setting your runtime to GPU\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-43b45a64c45e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mweight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"drive/My Drive/evaluation_small/weights_word_detection_small_new20.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/evaluation_small/weights_word_detection_small_new20.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyqEBOFt2Ifs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_epochs = 100\n",
        "val_list = []\n",
        "train_list = []\n",
        "percent_val = 0.5\n",
        "for epoch in range(20, total_epochs):\n",
        "    print(\"EPOCH:\", epoch + 1)\n",
        "    print(\"TRAIN\")\n",
        "    train(train_data, model, optimizer, device)\n",
        "    print(\"VALIDATION\")\n",
        "    val_list.append(validate(test_data, model, device, percent_val))\n",
        "    train_list.append(validate(train_data[:15], model, device, percent_val))\n",
        "    if((epoch + 1) % 10 == 0):\n",
        "        torch.save(model, \"weights_word_detection_small\" + str(epoch) + \".pt\")\n",
        "    if((epoch+1) % 5 == 0):\n",
        "        torch.save(model, \"/content/drive/My Drive/\" + \"weights_word_detection_small_new\" + str(epoch +1) + \".pt\")\n",
        "        for lis in train_list:\n",
        "            print(lis)\n",
        "        for lis in val_list:\n",
        "            print(lis)\n",
        "        \n",
        "\n",
        "torch.save(model, \"/content/drive/My Drive/\" + \"weights_word_detection_small50.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVeFPi3TfQj3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}